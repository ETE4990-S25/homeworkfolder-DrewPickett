import requests
import xmltodict
import json
import random
from datetime import date, timedelta, datetime
import time
import os
from queue import Queue, Empty
from threading import Thread

rates = ["EUR", "GBP", "USD", "DZD", "AUD", "BWP", "BND", "CAD", "CLP", "CNY", "COP", "CZK", "DKK", "HUF", "ISK", "INR", "IDR", "ILS", "KZT", "KRW", "KWD", "LYD", "MYR", "MUR", "NPR", "NZD", "NOK", "OMR", "PKR", "PLN", "QAR", "RUB", "SAR", "SGD", "ZAR", "LKR", "SEK", "CHF", "THB", "TTD"]

ratesForBase = [r for r in rates if r != "USD" and r != "EUR" and r != "GBP"]

base = random.choice(ratesForBase)

start_date = datetime.strptime("2011-05-04", "%Y-%m-%d").date()
end_date = date.today()

output_folder = f"{base}_exchange_rate_data"
os.makedirs(output_folder, exist_ok=True)

def download(base, start_date, end_date,):
    date_str = date_obj.strftime("%Y-%m-%d")
    file = os.path.join(output_folder, f"{date}.json")
        
        # URL of the XML data
    url = f"https://www.floatrates.com/historical-exchange-rates.html?operation=rates&pb_id=1775&page=historical&currency_date={current_date}&base_currency_code={base}&format_type=xml"
    try:

            # Fetch the XML data
        response = requests.get(url)
        response.raise_for_status()  # Ensure we notice bad responses
        
        try:

                # Parse the XML data to a Python dictionary
            data_dict = xmltodict.parse(response.text)

            with open(file, "w") as json_file:
                json.dump(data_dict, json_file, indent=4)

        except Exception:
            pass

    except Exception:
        pass

    time.sleep(0.25)

def worker(work_queue):
    while not work_queue.empty():
        try:
            date_obj = work_queue.get(block=False)
        except Empty:
            break
        else:
            download(date_obj)
            work_queue.task_done()

def threaded_pool():
    work_queue = Queue()
    current_date = start_date
    all_dates = []

    while current_date <= end_date:
        work_queue.put(current_date)
        all_dates.append(current_date)
        current_date += timedelta(days=1)

    threads = [
        Thread(target=worker, args=(work_queue,))
        for _ in range(THREAD_POOL_SIZE)
    ]
    
    for thread in threads:
        thread.start()

    work_queue.join()

    while threads:
        threads.pop().join

data = download(base, start_date, end_date)
save(data, start_date, end_date)